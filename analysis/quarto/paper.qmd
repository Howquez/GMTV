---
title: Growth and inequality in public good provision | an extended replication
author:
  - name: Hauke Roggenkamp
    email: hauke.roggenkamp@unisg.ch
    affiliations:
        - id: HSU
          name: Helmut Schmidt University
          department: Department of Economics
          address:  Holstenhofweg 85
          city: Hamburg
          state: Germany
          postal-code: 22043
        - id: HSG
          name: University of St. Gallen
          department: Institute for Behavioral Science and Technology
          address: Torstrasse 25
          city: St. Gallen
          state: Switzerland
          postal-code: 9000
    # attributes:
    #     corresponding: true
    # note: This is the first author footnote.
abstract: |
  This is the abstract. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum augue turpis, dictum non malesuada a, volutpat eget velit. Nam placerat turpis purus, eu tristique ex tincidunt et. Mauris sed augue eget turpis ultrices tincidunt. Sed et mi in leo porta egestas. Aliquam non laoreet velit. Nunc quis ex vitae eros aliquet auctor nec ac libero. Duis laoreet sapien eu mi luctus, in bibendum leo molestie. Sed hendrerit diam diam, ac dapibus nisl volutpat vitae. Aliquam bibendum varius libero, eu efficitur justo rutrum at. Sed at tempus elit.
keywords: 
  - Replication study
  - Non-convenience sample
  - Open science
  - Dynamic public good game
  - Online experiment
  - Generalizability
date: last-modified
bibliography:  ../biblio.bib
format:
  elsevier-pdf:
    keep-tex: true
    journal:
      name: Journal of Behavioral and Experimental Economics
      formatting: preprint
      model: 3p
      cite-style: authoryear
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r packages}
# install this package once, it'll then install and load all remaining packages
# install.packages("pacman")

pacman::p_load(magrittr, data.table, stringr, lubridate, glue, DescTools, haven,
               stargazer, ggplot2, patchwork, MetBrewer, Rmisc)
```

```{r design}
# ggplot layout
layout <- theme(panel.background = element_rect(fill = "transparent", color = NA),
                plot.background = element_rect(fill = "transparent", color = NA),
                panel.grid = element_blank(),
                panel.grid.major.y = element_blank(),
                legend.key = element_rect(fill = "transparent"),
                axis.line = element_line(size = 0.25),
                axis.ticks = element_line(size = 0.25),
                axis.title = element_text(size = 8),
                legend.text = element_text(size = 8),
                plot.caption = element_text(size = 6,
                                            colour = "#555555"),
                legend.title = element_blank()
)

# color
colors <- met.brewer(name="Tam",n=7,type="discrete")
cPrimary = "#ffd353"
cSecondary = "#9f2d55"
cInfo = "#34168"
```

<!-- OUR DATA -->


```{r readAllData}
# identify files of all sessions
files <- list.files(path = "../../data/replication/",
                       recursive = TRUE,
                       full.names = TRUE)

# load all of them into a list
csvs <- list()
for(i in files){
  name <- str_extract(string = i, pattern = "2021.*")
  temp <- read.csv(i, stringsAsFactors = FALSE) %>% data.table()
  csvs[[name]] <- temp
}

# bind list into single data table
full <- rbindlist(l = csvs, use.names = TRUE) %>% data.table()

# ignore observations who have not made it to the first contribution
DT <- full[participant._index_in_pages > 2 & 
             participant.time_started != "" & 
             participant.label != "" &
             !(is.na(dPGG.1.player.contribution))]

# tidy up
rm(list = c("files", "csvs", "i", "name", "temp"))
```

```{r metaData}
# aggregate each session's meta data
meta_long <- full[participant.time_started != "" & 
                    participant.label != "",
                  .(session.code,
                    participant.label,
                    participant.time_started,
                    dPGG.1.player.contribution)]

# reformat time stamp in new variables
meta_long[, `:=`(date = participant.time_started %>% ymd_hms() %>% date(),
                 hour = participant.time_started %>% ymd_hms() %>% hour())]

# aggregate and count 
meta <- meta_long[,
                  .(date = date %>% unique(),
                    time = hour %>% unique() %>% paste("00", sep = ":"),
                    showups = participant.time_started %>% length(),
                    dropouts = dPGG.1.player.contribution %>% is.na() %>% sum(na.rm = FALSE)),
                  by = session.code]

# get number of participants and observations (groups of 4)
meta[,
     `:=`(participants = showups - dropouts,
          observations = (showups - dropouts)/4)]

# save data
fileName <- "replication2021"
save(meta, file = paste0("../../data/processed/rda/", fileName, "_meta", ".rda"))
write.csv(meta, file = paste0("../../data/processed/csv/", fileName, "_meta", ".csv"))

rm(list = c("full", "meta_long"))
```

```{r identifyStudents}
# we had to invite students as the general population sample was exhausted, unfortunately. let's identify them:
invitedStudents <- read.table(file = "../../data/sample/invited_students.txt", col.names = c("participant.label")) %>%
  data.table()
# note that these students participated in the ultimate session
```

```{r focusOnFirstRound}
# create data table 
replicationFirstRound <- DT[,
                 .(participant.code,
                   treatment = "replication",
                   session.code,
                   groupID = paste(session.code, dPGG.1.group.id_in_subsession, sep = "_"),
                   othersContribution = dPGG.1.group.total_contribution - dPGG.1.player.contribution,
                   ownContribution = dPGG.1.player.contribution,
                   trust = Outro.1.player.PQ11,
                   comprehension = dPGG.10.player.comprehension)]

# save data
save(replicationFirstRound, file = paste0("../../data/processed/rda/", fileName, "_R1", ".rda"))
write.csv(replicationFirstRound, file = paste0("../../data/processed/csv/", fileName, "_R1", ".csv"))
```

```{r subsetData}

# identify most relevant variables
mRegex <- "participant\\.code$|session\\.code$|dPGG\\.1\\.group\\.id_in_subsession|^dPGG.1.player.id_in_group$|\\.1\\.player.belief|endowment|contribution|stock|gain$|bot_active|10.player.comprehension|10.player.donation"
mainVariables <- str_subset(string = names(DT), pattern = mRegex)

# prune all other variables
subset <- DT[, ..mainVariables]

# tidy up
rm(list = c("mRegex", "mainVariables"))
```

```{r addNewVariables}
# refactor groupID such that it eventually contains treatment-info
subset[, groupID := paste(session.code, 
                          dPGG.1.group.id_in_subsession,
                          sep = "_")]

# add share as contribution/endowment
for(round in 1:10){
  contribution <- glue("dPGG.{round}.player.contribution")
  endowment <- glue("dPGG.{round}.player.endowment")
  subset[, glue("dPGG.{round}.player.share") := subset[[contribution]]/subset[[endowment]] ]
}

# add treatment variable
subset[,
       treatment := "replication"]
```

```{r calculateAggregates}
# we need to aggregate some outcomes on a groupID level (per sessions per treatment)
# we'll do so using a loop
# this will yield a list of data tables that will be merged to a list eventually.
cluster <- c("treatment", "session.code", "groupID")
outcomes <- c("contribution", "endowment", "stock", "gain", "bot_active")

DTs <- list()
for(outcome in outcomes){
  if(outcome == "bot_active"){
    var = names(subset) %>% str_subset(pattern = glue("group\\.{outcome}$"))
  } else {
    var = names(subset) %>% str_subset(pattern = glue("player\\.{outcome}$"))
  }


  # calculate either averages or the sum per round per group
  aggregates = subset[, lapply(.SD, sum, na.rm=TRUE), 
                      by = cluster, 
                      .SDcols=var]
  
  # transform from wide to long
  meltedAggregates <- melt(aggregates, id.vars = cluster, measure.vars = var)
  DTname <- glue("{str_to_title(outcome)}")
  DTs[[DTname]] <- meltedAggregates
  rm(list = c("DTname", "meltedAggregates", "aggregates", "var", "outcome"))
}
```

```{r renameVariables}
# each data table in that list has the same column names.
# the outcomes are all named "value", for instance.
# now, we"ll infer the round number (contained in the variable name)
for(i in 1:length(outcomes)){
  DTs[[i]] <- DTs[[i]][,
                       .(treatment,
                         session.code,
                         groupID,
                         round = str_replace_all(string = variable,
                                                 pattern = "\\D", 
                                                 replacement="") %>% as.integer(),
                         value # to be renamed afterwards
                       )
  ]
  # rename "value" to outcome variable
  setnames(DTs[[i]], old = "value", new = outcomes[i])
}

# tidy up
rm("i")
```


```{r calculateGini}
# repeat everything for the gini
var = names(subset) %>% str_subset(pattern = "player\\.stock$")
gini = subset[,
              lapply(.SD, Gini, na.rm=TRUE), 
                by = cluster, 
                .SDcols=var
              ]
Gini <- melt(gini, id.vars = cluster, measure.vars = var)

DTs[["Gini"]] <- Gini[,
                    .(treatment,
                      session.code,
                      groupID,
                      round = str_replace_all(string = variable,
                                              pattern = "\\D", 
                                              replacement="") %>% as.integer(),
                      gini = value
                       )]
rm(list = c("var", "gini", "Gini"))

# note that GMTV used start of period earnnings, i.e. endowments. We use end of period earnings, i.e. stock.
# this adjustment has been considered in our processing of GMTVs data.
```


```{r mergerEverything4FinalData}
# now merge every table in the list to one final data table called "replication"
replication <- Reduce(function(...) merge(..., by=c(cluster, "round"), all = TRUE), DTs)

# tidy up
rm(list = c("cluster", "contribution", "endowment", "round", "DTs", "outcomes"))
```

```{r calculateShare}
# define the share (one of the main outcome variables) as 
# the sum of contributions devided by the sum of endowments
replication[, share := contribution/endowment]
```

```{r defineRichGroups}
# use the median to differentiate between poor and rich groups (as GMTV did)
median <- replication[round == 10,
                      median(stock)]

# find the groups that end up rich or poor
richGroups <- replication[round == 10 & stock > median,
                          unique(groupID)] 

poorGroups <- replication[round == 10 & stock < median,
                          unique(groupID)]

# mark these groups for each period
replication[groupID %in% richGroups,
            rich := TRUE]

replication[groupID %in% poorGroups,
            rich := FALSE]

# tidy up
rm(list = c("median", "poorGroups", "richGroups"))

```

```{r misc}
# flag observations where at least one participant did not understand the game
noComp <- subset[dPGG.10.player.comprehension == 0,
                 groupID] %>% unique()
replication[,
     noComprehension := 0]
replication[groupID %in% noComp,
     noComprehension := 1]


# drop observations (i.e. groups in rounds) with dropouts (bot_active == 1) and
# where round > 10
replication <- replication[bot_active == 0 & round <= 10]

# tidy up
rm("noComp")
```

```{r saveData}
save(replication, file = paste0("../../data/processed/rda/", fileName, ".rda"))
write.csv(replication, file = paste0("../../data/processed/csv/", fileName, ".csv"))
```

```{r createCovariates}

# so far, I neglected many variables in what happened before. The following few lines
# deal with some of these variables in a similar procedure


# add variables
DT[, treatment := "replication"]
DT[, groupID := paste(session.code, dPGG.1.group.id_in_subsession, 
                    sep = "_")]

# subset
cRegex <- "participant.code|session.code|treatment|groupID|Outro.1.player|10.player.donation|10.player.stock|switching_row|inconsistent"
covariates <- str_subset(string = names(DT),
                            pattern = cRegex)
CT <- DT[, ..covariates]

# rename
names(CT) <- names(CT) %>% 
  str_replace_all(pattern =".*player\\.",
                  replacement = "") %>%
  str_to_lower()
names(CT)[names(CT) == "groupid"] <- "groupID"

# refactor
CT[, donation := donation/20] # exchange rate tokens to real world currency 1/20
CT[donation %>% is.na, donation := 0]
CT[, gender := ifelse(test = gender == "female",
                      yes  = 1,
                      no   = 0)]
CT[, inconsistent := as.logical(inconsistent)]

# reassign payoff (with stock of the last period)
CT[, payoff := stock]
CT[, stock := NULL]

# write data
replicationCovariates <- CT
save(replicationCovariates, 
     file = paste0("../../data/processed/rda/", fileName, "_COVS", ".rda"))
write.csv(replicationCovariates, 
          file = paste0("../../data/processed/csv/", fileName, "_COVS", ".csv"))

# tidy up
rm(list = c("CT", "cRegex", "covariates"))
```

```{r readTime}
# as before, we need to read a list of files (measuring the time spent per page)

# identify files
files <- list.files(path = "../../data/pageTimes/",
                       recursive = TRUE,
                       full.names = TRUE)

# loop
csvs <- list()
for(i in files){
  name <- str_extract(string = i,
                      pattern = "2021.*")
  
  temp <- read.csv(i, 
                   stringsAsFactors = FALSE) %>%
    data.table()
  
  csvs[[name]] <- temp
}

# bind files list to data.table
timeSpent <- rbindlist(l = csvs,
                       use.names = TRUE) %>%
  data.table()

# set oder
setorder(timeSpent, session_code, participant_code, epoch_time)

# tidy up
rm(list = c("files", "i", "name", "temp"))
```


```{r calcDuration}
# shift rows to calculate this duration (per page) as the distance between
# the current and the next time stamp
timeSpent[,
          lag := shift(epoch_time, fill = NA, type = "lag"),
          by = c("session_code", "participant_code")]

timeSpent[,
          duration := epoch_time - lag,
          by = c("session_code", "participant_code")]

# calculate overall time spent as the difference between the min and max time stamp
timeSpent[,
          completion := epoch_time %>% max() - epoch_time %>% min(),
          by = c("session_code", "participant_code")]

# create new data table with selected columns
duration <- timeSpent[participant_code %in% DT$participant.code,
                      .(
                        session_code,
                        participant_code,
                        app_name,
                        page_name,
                        page_index,
                        page_submission = epoch_time,
                        time_spent = duration,
                        completion_time = completion
                      )]

# save data
save(duration, file = paste0("../../data/processed/rda/", fileName, "_timeSpent", ".rda"))
write.csv(duration, file = paste0("../../data/processed/csv/", fileName, "_timeSpent", ".csv"))

# tidy up
rm(list = c("timeSpent", "csvs", "DT"))
```




<!-- ORIGINAL (GMTV) DATA -->

```{r readGMTV}
# having done all that, we need to prepare the original data and bind it to ours
# I'll thus, start by reading the orginal data

DT <- read_dta(file="../../data/gaechteretal/GMTV-data.dta") %>% data.table()
CT <- read_dta(file="../../data/gaechteretal/GMTV-questionnaire-data.dta") %>% data.table()
```

```{r subsetGMTV}
# because we only replicate one of their treatments, I subset accordingly
# noPunish10 <- DT[exp_num == 5 | exp_num == 8 | exp_num == 9]
noPunish10 <- DT[longgame == 0 & punish == 0 & exp_num <= 10]
```

```{r newVariablsGMTV}
# calculate the share of endowments contributed
noPunish10[,
           share := sum/gdp,
           by = .(subj_id, per)]

# calculate gini based on endowments (as GMTV did)
noPunish10[,
           gini2 := Gini(c(tokens, other1, other2, other3)),
           by = .(subj_id, per)]

# calculate gini based on stock (i.e. end of period earnings)
noPunish10[, stock0 := (tokens - putin + 1.5*sum/4) %>% ceiling()]
noPunish10[, stock1 := (other1 - pu1 + 1.5*sum/4) %>% ceiling()]
noPunish10[, stock2 := (other2 - pu2 + 1.5*sum/4) %>% ceiling()]
noPunish10[, stock3 := (other3 - pu3 + 1.5*sum/4) %>% ceiling()]
noPunish10[, 
           gini3 := Gini(c(stock0, stock1, stock2, stock3)),
           by = .(subj_id, per)]
```

```{r createGMTVtable}
# select columns we are interested in and rename a few to match our data

GMTV <- noPunish10[order(gr_id, per),
           .(treatment = "noPunish10", 
             session.code = exp_num,
             groupID = gr_id, 
             round = per,
             contribution = sum,
             endowment = gdp,
             share,
             stock = (gdp + ceiling(sum/4*1.5)*4-sum),
             gain = (ceiling(sum/4*1.5)*4-sum),
             gini = gini3,
             bot_active = 0,
             noComprehension = NA)] %>% unique()

# tidy up
rm(list = c("noPunish10"))
```

```{r richPoorGMTV}
 # create rich indicator (just as highgdp in original data)
median <- GMTV[round == 10,
                   median(stock)]

richGroups <- GMTV[round == 10 & stock > median,
                       unique(groupID)] 

poorGroups <- GMTV[round == 10 & stock < median,
                       unique(groupID)]

GMTV[groupID %in% richGroups,
         rich := TRUE]

GMTV[groupID %in% poorGroups,
         rich := FALSE]

# tidy up
rm(list = c("median", "richGroups", "poorGroups", "fileName"))
```

```{r saveGMTV}
fileName <- "GMTV2017"
# save data
save(GMTV, file = paste0("../../data/processed/rda/", fileName, ".rda"))
write.csv(GMTV, file = paste0("../../data/processed/rda/", fileName, ".csv"))
```


```{r calcSwitchingPoint}
# GMTV gathered some risk data that I'll process in a separate DT and merge it
# with other covariates later on

GMTVRisk <- CT[exp_num == 5 | exp_num == 8 | exp_num == 9,
               .(participant.code = subj_id,
                 e10, e20, e30, e40, e50, e60, e70,
                 inconsistent = ifelse(test = e60 < e70 | e50 < e60 | e40 < e50 | e30 < e40 | e20 < e30 | e10 < e20,
                                       yes  = TRUE,
                                       no   = FALSE)
                 )]

GMTVRisk[,
         switching_row := ifelse(test = inconsistent == TRUE,
                                yes  = NA,
                                no   = e10 + e20 + e30 + e40 + e50 + e60 + e70 + 1 + 2) # because GMTV used a 7-point-likert scale
         ]
```

```{r subsetCovariates}
# subset covariate data and rename+refactor some variables
temp <- CT[exp_num == 5 | exp_num == 8 | exp_num == 9,
                         .(treatment = "noPunish10",
                           session.code = exp_num,
                           groupID = gr_id,
                           participant.code = subj_id,
                           gender,
                           age = Sys.Date() %>% lubridate::year() - age,
                           pq01 = q1,
                           pq02 = q2,
                           pq03 = q3,
                           pq04 = q4,
                           pq05 = q5,
                           pq06 = q6,
                           pq07 = q7,
                           pq08 = q8,
                           pq09 = q9,
                           pq10 = q10,
                           pq11 = q11,
                           pq12 = q12,
                           pq13 = q13,
                           pq14 = q14,
                           donation = don
                           )]

temp[donation %>% is.na, donation := 0]

```

```{r mergeAndWrite}

GMTVCovariates <- data.table::merge.data.table(x = temp,
                                               y = GMTVRisk[, .(participant.code, inconsistent, switching_row)],
                                               by = c("participant.code"))

# write data
save(GMTVCovariates, 
     file = paste0("../../data/processed/rda/", fileName, "_COVS", ".rda"))
write.csv(GMTVCovariates, 
          file = paste0("../../data/processed/csv/", fileName, "_COVS", ".csv"))

# tidy up
rm(list = c("temp", "GMTVRisk"))
```

```{r firstRound}
noPunish <- DT[exp_num == 1 | exp_num == 3 | # noPunish15
                 exp_num == 5 | exp_num == 8 | exp_num == 9] # noPunish10

temp <- noPunish[per == 1]
temp <- temp[,
             treatment := "noPunish10"]
temp <- temp[exp_num == 1 | exp_num == 3,
             treatment := "noPunish15"]

GMTVFirstRound <- temp[,
                           .(participant.code = subj_id,
                             treatment,
                             session.code = exp_num,
                             groupID = gr_id,
                             othersContribution = sumputin - putin,
                             ownContribution = putin,
                             trust = NA,
                             comprehension = NA)]

# save data
save(GMTVFirstRound, 
     file = paste0("../../data/processed/rda/", fileName, "_R1", ".rda"))
write.csv(GMTVFirstRound, 
          file = paste0("../../data/processed/csv/", fileName, "_R1", ".csv"))

rm(list = c("temp", "fileName"))
```

<!-- MERGE & TUNE DATA -->

```{r rbindOursAndGMTV, eval = TRUE}
main <- rbindlist(list(replication, GMTV), 
                  use.names = TRUE)

R1   <- rbindlist(list(replicationFirstRound, GMTVFirstRound), 
                  use.names = TRUE)

covs <- rbindlist(list(replicationCovariates, GMTVCovariates), 
                  use.names = TRUE,
                  fill = TRUE)

rm(list = c("CT", "DT", "GMTV", "GMTVCovariates", "GMTVFirstRound", 
            "invitedStudents", "noPunish", "replication", "replicationCovariates",
            "replicationFirstRound", "subset"))
```

```{r treatmentAsFactor}
main[, treatment := as.factor(treatment)]
R1[, treatment := as.factor(treatment)]
covs[, treatment := as.factor(treatment)]
```

```{r studentSample}

# Two of these sessions were special: The first (`r meta[1, session.code]`) as well as the last one (`r meta[, session.code %>% tail(n=1)]`). The first session suffered technical problems such that the risk elicitation task was omitted. The last session (almost exclusively) relied on a student sample as our non-student sample was exhausted after the first three sessions. As a consequence, the last session was conducted with 59 students while all others were conducted without any students. I'll therefore create a boolean `student` variable. Becaue all of the original experiments were conducted with students, `student` also equals 1 in the "noPunish10" treatments

main[, student := FALSE]
main[session.code == "d6jrsxnr" | treatment == "noPunish10",
     student := TRUE]

R1[, student := FALSE]
R1[session.code == "d6jrsxnr" | treatment == "noPunish10",
   student := TRUE]
```



<!-- PAPER STARTS HERE -->

<!-- 
# Key Takeaways

- We **[replicate](#gmtv-replication)** a public goods experiment with dynamic inter-dependencies and find similar results as @GMTV2017. 
    + Absolute contributions increase over time.
    + Just as in _static_ public goods experiments, the share of endowments contributed decreases over time.
    + The richest groups earn fifteen times more than the poorest groups.
    + While there clearly is growth, groups do not realize the maximal potential efficiency and earn just over `r main[treatment == "replication" & round == 10, mean(stock)/(80*1.5^10)*100] %>% round(digits=1)`% of what is possible.
- Varying the subject pool and including a voluntary climate action (VCA), we have a setup similar to @GKLS2020, which allows us to assess **[generalizability](#generalizability)**.^[Note that one can easily model the VCA as a dictator game, which relates to a literature summarized by @cartwright2022.]
- Studying a general population sample online, synchronously and over the course of multiple periods, we find that classic **[lab procedures](online-methodology)** can be applied outside of the lab too.
    + Even though we conducted the experiment online and remotely, dropouts (or "attrition") are no concern.
    + Relying on an inexperienced non-convenience sample that cannot interact with experimenters, `r trunc((R1[comprehension > 1] %>% NROW() / R1[!(is.na(comprehension))] %>% NROW())*100)`% of all participants stated that they understood the game.
    + Participants make relatively fast decisions which makes longer games feasible in the future.^[Taken together with inefficient growth and the lack of dropouts, additional rounds are fairly cheap.]

-->

# Introduction
> "There are two possible articles you can write: (a) the article you planned to write when you designed your study or (b) the article that makes the most sense now that you have seen the results. They are rarely the same, and the correct answer is (b)." [@bemwriting, p. 171]


# Methodology

In the terminology of @Hamermesh2007, I ran both a _pure_ as well as a _scientific replication_ of one treatment arm of @GMTV2017's dynamic public good game. The pure replication re-analyzes the original data. [Appendix A](#A:-Pure-Replication) documents [errors I identified]() in the original paper. The scientific replication, where I utilize a different sample drawn from a different population in a different situation, is described in this section.

## Procedure

Participants entered the experiment at appointed times remotely from home. They first saw a welcome screen. After agreeing to the privacy policy, they could proceed to the instructions individually. Having read these instructions, each participant has also seen a demo-screen explaining the user interface. Before proceeding, they had to answer six comprehension questions correctly. Subsequently, they saw a waiting screen until they could be matched with three other participants, who have answered the comprehension questions correctly. Once matched, they were exposed to the decision screen over ten periods. At the end of the last period, participants saw results of all periods. Subsequently, they were exposed to a voluntary climate action, where they could donate (some of) their earnings to offset carbon dioxide. Subsequently, I elicited risk preferences [@HoltLaury2002] and finished with @GMTV2017's questionnaire.

## Experimental Design

As in the NOPUNISH 10 Period treatment arm of @GMTV2017, I ran sessions with groups of four ($i \in I=\{1,2,3,4\}$), an initial endowment of $N_i^1 = 20$ tokens, $T=10$ rounds, a private account with a return of $1$ and a group account with a return of $1.5$ ($\Rightarrow$ MPCR$\equiv \frac{1.5}{4}$), such that:

$$
N_i^{t+1}=N_i^t - c_i^t + \frac{1.5}{4}\sum_{j=1}^4 c_j^t
$$
Instead of receiving fresh endowments every period, participants receive one initial endowment only at the beginning of the first period. A participant's subsequent endowment equals her profit from the current period such that a decision in one period has consequences on her future endowments. For this reason, the game is described as a _dynamic_ public good game

## Sample

I recruited the participants from the so called _[HamburgPanel](https://www.wiso.uni-hamburg.de/forschung/forschungslabor/umfragelabor/aktuelle-umfragen/hamburgpanel.html)_ using HROOT [@hroot]. The panel is provided by the University of Hamburg's Research Laboratory, which used a randomized last digits approach to build the panel while drawing from the population of citizens from Hamburg, Germany.

Describe sample properties here.



## Software

The experiment was created using oTree [@oTree] and can be found on [GitHub](https://github.com/Howquez/coopUncertainty).

# Results

## Online Feasibility

How did the participants, who have never participated in a online group experiment before, cope with the situation? 

```{r plotTime}
#| fig.cap: Average Time Spent for each Contribution per Period

N <- duration[, participant_code %>% unique() %>% length()]
plotDT <- duration[app_name == "dPGG" & page_name == "dPGG_Decision",
                   .(time_spent = time_spent %>% sum()),
                   by = c("session_code", "participant_code", "page_index", "page_name")]

plotDT[, round := seq(from = 1, to = 10), by = c("participant_code")]

upperLimit <- plotDT[, time_spent %>% mean(), by = c("round")] %>% max()



ggplot(data = summarySE(data = plotDT,
                        measurevar = "time_spent",
                        groupvars=c("round"),
                        na.rm = FALSE,
                        conf.interval = 0.95,
                        .drop = TRUE),
       mapping = aes(x = round, y = time_spent)) +
  layout +
  theme(legend.position="bottom") +
  geom_line(show.legend=FALSE, color = cSecondary, lty=2) +
  geom_errorbar(aes(ymin=time_spent-ci, ymax=time_spent+ci), width=.25, alpha = 0.5, color = cSecondary) +
  geom_point(color = cSecondary) +
  scale_x_continuous(name="",  breaks = 1:10) +
  scale_y_continuous(limits = c(0, upperLimit + 10), expand = c(0, 0)) +
  labs(y = "Time Passed in Seconds", caption = "Bars indicate 95% confidence intervals.") +
  theme(plot.margin = margin(0.25,1,0.25,0.25, "cm"))
```

## Pre-registered GMTV Replication

**Result 1.** _The `NOPUNISH 10` treatment of @GMTV2017 can be replicated because the replication data resemble the original data with respect to initial and final contributions, wealth and growth as well as inequality between and within groups._

This is remarkable given the different sample and language, the different software and user interface  as well as the online setting during the COVID19 pandemic.

### Contributions

```{r prepFirstSummary}
replication <- R1[treatment == "replication", ownContribution]
GMTV    <- R1[treatment == "noPunish10", ownContribution]


rows <- sapply(X = list(replication, GMTV), FUN = NROW) %>% max()
temp <- data.frame(replication = c(replication, rep(NA, rows - NROW(replication))),
                   GMTV = c(GMTV, rep(NA, rows - NROW(GMTV))))

rs1 <- wilcox.test(replication, 
                   GMTV,
                   exact = FALSE)$p.value %>% 
  round(digits = 4) %>% 
  formatC(format = "f", 
          digits = 4)
```

First, I ask whether the samples differ with respect to their initial contributions to the public good. Is our replication sample more pro-social than the original sample? Figure 1 reveals that it is not. The distributions of both samples look fairly similar. Both samples contributed 10 tokens, that is, 50% of their endowments on average (median and mean).^[The two-sided rank sum test (comparing differences between samples) yields a p-Value of `r rs1` for the mean contribution in first round of the game.] Moreover, both samples' initial contributions resemble initial contributions participants usually make in the standard game with partner matching.^[See Figure 3B in @fehrgaechter2000 (p.989), for instance.] However, in the dynamic game presented here, we are particularly interested in the subsequent periods because differences add up exponentially. Do the two groups remain similar over the course of time?


```{r firstRoundViz}
#| fig.cap: Individual contributions to the dynamic public good in the first period

ggplot(data = R1[treatment != "noPunish15"],
       mapping = aes(x = ownContribution, fill = treatment, lty = treatment)) +
  geom_density(alpha = 0.5) +
  scale_x_continuous(limits = c(0, 20),
                       expand = c(0, NA)) +
  scale_y_continuous(limits = c(0, 0.1),
                       expand = c(0, NA)) +
  scale_fill_manual(values = c(cPrimary, cSecondary),
                    labels = c("Original Sample", "Replication Sample")) +
  guides(lty = "none") +
  geom_vline(xintercept = R1[treatment == "replication", 
                             mean(ownContribution)],
             col = "#FFFFFF",
             lty = 2) +
  geom_vline(xintercept = R1[treatment == "noPunish10", 
                             mean(ownContribution)],
             col = "#FFFFFF",
             lty = 1) +
    labs(title = "", 
       y = "", x = "Initially Contributed Tokens",
       caption = "White lines indicate means (dashed line = replication sample).") +
  layout +
  theme(legend.position = "top")
```


```{r firstRoundSummary}
#| results: asis
#| warning: false
#| fig.cap: "test"
#| eval: false

if(knitr::is_html_output()){
  type <- "html"
} else {
  type = "latex"
}

stargazer(temp,
          summary.stat = c("mean", "median","sd", "max", "min", "n"),
          type = type, 
          flip = TRUE, 
          header=FALSE)
```


In particular, do the two samples' contributions follow the same path over the 10 periods they played? The answer is _no_. Figure 2 illustrates that the samples make similar contributions at the beginning and the end of the game but behave differently in between. More precisely, the left panel--depicting the average contributions in absolute terms--shows that the original sample contributed substantially more than the replication sample _in all but the first and last periods_. For this reason, the original sample's behavior differs from the replication sample's behavior in two aspects: it contributes more and exhibits a considerable drop in the last period (whereas the replication sample's contributions flatten). 

Note that increasing contributions over time imply increasing endowments over time. Hence, absolute contributions do not us much about the willingness to cooperate. For this reason, the right panel in Figure 2 shows the average _share of endowments contributed_ over time. Both samples exhibit a similar pattern: they decline and do not stabilize. However, both samples also differ with respect to one aspect: the replication sample's share of contributions declines faster.


```{r plotContributions}

SUM <- main[,
            lapply(.SD, mean, na.rm = TRUE),
            by = c("round", "treatment"),
            .SDcols = "contribution"]

SUM[,
    sum := round(contribution)]

SUM[,
    contribution := contribution/4]

upperLimit <- SUM$contribution %>% max() %>% round() + 5

p1 <- ggplot(data = SUM, 
             aes(x = round, y = contribution, fill = treatment, color = treatment, lty = treatment)) +
  layout +
  theme(legend.position="top") +
  geom_line(show.legend=FALSE) +
  geom_point() +
  scale_x_continuous(name="",  breaks = 1:15) +
  scale_y_continuous(limits = c(0, upperLimit), expand = c(0, 0)) +
  labs(y = "Average Amount of Tokens contributed") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample")) + 
  guides(fill = "none") +
  theme(plot.margin = margin(0.25,1,0.25,0.25, "cm"))

rm(list = c("SUM"))
```


```{r plotShareOfContributions}
#| fig.cap: "The average amount of tokens contributed over time in treatments."

SHARE <- main[,
            lapply(.SD, mean, na.rm = TRUE),
            by = c("round", "treatment"),
            .SDcols = "share"]

# SHARE <- main[,
#             .(share = sum(contribution)/sum(endowment)),
#             by = c("round", "treatment")]

upperLimit <- 0.75

p2 <- ggplot(data = SHARE, 
             aes(x = round, y = share, fill = treatment, color = treatment, lty = treatment)) +
  layout +
  theme(legend.position="bottom") +
  geom_line(show.legend=FALSE) +
  geom_point() +
  scale_x_continuous(name="",  breaks = 1:15) +
  scale_y_continuous(limits = c(0, upperLimit), expand = c(0, 0)) +
  labs(y = "Share of Current Endowment contributed") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample")) +
  guides(fill = "none")

p1 + p2 + plot_layout(guides = "collect") & 
  theme(legend.position = "top")

# rm(list = c("p1", "p2"))
```


Again, both samples' behavior resembles the contributions participants usually make in the standard game with partner matching: contributions equal approximately half of endowments in the very first period and decrease to around 10% of endowments by the last period.^[The right panel is thus, comparable to the visualizations _and results_ in the standard game. See, for instance, Figure 1B in @fehrgaechter2000 (p.986).] In the dynamic game presented here, however, different paths lead to different levels of wealth -- even if they share the same start- and end-points. I am thus, more interested in the contributions' implications for wealth generation and growth. 

### Wealth Creation

```{r summaryWealth}
#| results: asis
#| warning: false
#| fig.cap: "test"

if(knitr::is_html_output()){
  type <- "html"
} else {
  type = "latex"
}

replication <- main[treatment == "replication" & round == 10, stock]
GMTV    <- main[treatment == "noPunish10" & round == 10, stock]

rs1 <- wilcox.test(replication, 
                   GMTV,
                   exact = FALSE)$p.value %>% 
  round(digits = 4) %>% 
  formatC(format = "f", 
          digits = 4)

```

```{r wealthVariables}
originalWealth    <- main[treatment == "noPunish10" & round == 10, mean(stock)]
replicationWealth <- main[treatment == "replication" & round == 10, mean(stock)]
```

How do the different contribution-paths translate into wealth?^[To measure wealth and growth, I define a variable called _stock_ which sums the endowments of all participants in a given group at the end of the round (that is, after the contributions have been made, multiplied and redistributed).] Given that the original sample contributed more in most of the periods, one would expect the respective groups to be considerably more wealthy. Figure 3 indicates just that. The grey lines show that an average group in the original sample accumulated about `r round(originalWealth)` tokens. In contrast, an average group in the replication sample accumulated about `r round(replicationWealth)` tokens. This difference is insignificant at conventional levels^[The two-sided rank sum test (comparing differences between samples) yields a p-Value of `r rs1` for the mean stock in last round of the game.] though.

```{r stockDistributionViz}
#| fig.cap: Groups' income at the end of the game

ggplot(data = main,
       mapping = aes(x = stock, fill = treatment, lty = treatment)) +
  geom_density(alpha = 0.5) +
  scale_x_continuous(limits = c(0, NA),
                       expand = c(0, NA)) +
  scale_y_continuous(limits = c(0, NA),
                       expand = c(0, NA)) +
  scale_fill_manual(values = c(cPrimary, cSecondary),
                    labels = c("Original Sample", "Replication Sample")) +
  guides(lty = "none") +
  geom_vline(xintercept = replicationWealth,
             col = "#000000", alpha = 0.5,
             lty = 2) +
  geom_vline(xintercept = originalWealth,
             col = "#000000", alpha = 0.5,
             lty = 1) +
    labs(title = "", 
       y = "", x = "Stock",
       caption = "Grey lines indicate means (dashed line = replication sample).") +
  layout +
  theme(legend.position = "top")
```

```{r overallGinis}
rG <- main[round == 10 & treatment == "replication",
           .(stock = sum(stock)),
           by = groupID][, Gini(stock)] %>% round(digits = 2)

oG <- main[round == 10 & treatment == "noPunish10",
           .(stock = sum(stock)),
           by = groupID][, Gini(stock)] %>% round(digits = 2)

rSD <- main[round == 10 & treatment == "replication",
            .(stock = sum(stock)),
            by = groupID][, sd(stock)] %>% round(digits = 2)

oSD <- main[round == 10 & treatment == "noPunish10",
            .(stock = sum(stock)),
            by = groupID][, sd(stock)] %>% round(digits = 2)
```

Although there clearly is growth, groups do not realize the maximal potential efficiency: under full cooperation, a group can accumulate at least `r (80*1.5^10) %>% trunc()` tokens or EUR `r (80*1.5^10 /20) %>% trunc()`. This is depicted in the left panel of Figure 4, where one can see the average wealth over time by sample. The panel illustrates for both samples that growth was continuous and surprisingly linear, given the exponential character of the game's design. To sum up, the contribution behavior differed between samples. In contrast, neither the eventual wealth nor the corresponding growth paths differed. Differences in contribution behavior did, thus, not translate in significantly different wealth outcomes.

Why? Perhaps because the heterogeneity within samples and across groups has been too large to _detect_ a significant difference. The right panel of Figure 4 depicts heterogeneity: In the replication sample, the richest group earned `r a <- main[treatment == "replication" & round == 10, max(stock)]; a` tokens (which is about `r round(a/80, digits = 2)*100`% of the initial endowment) whereas the poorest group ends up with `r b <- main[treatment == "replication" & round == 10, min(stock)]; b` tokens (`r round(b/80, digits = 2)*100`%). More broadly, the replication sample is characterized by inequality between groups ($SD_{Replication} =$ `r rSD`). The same holds true for the original sample ($SD_{Original} =$ `r oSD`). Hence, the heterogeneity across groups does not differ between samples, which is remarkable because the replication sample was drawn from a more heterogeneous (non-convenience sample). Does it differ within groups?

<!-- doch lieber Gini? statt SD reporten? -->

```{r plotStock .column-page}

# data
STOCK <- main[,
              lapply(.SD, mean, na.rm = TRUE),
              by = c("round", "treatment"),
              .SDcols = "stock"]

STOCKr <- main[rich == TRUE,
               lapply(.SD, mean, na.rm = TRUE),
               by = c("round", "treatment"),
               .SDcols = "stock"]

STOCKp <- main[rich == FALSE,
               lapply(.SD, mean, na.rm = TRUE),
               by = c("round", "treatment"),
               .SDcols = "stock"]


# annotation
maxPath <- data.table(x = 1:10)
maxPath[, y := 80*1.5^x]
maxPath[, treatment := "replication"]
maxPath[, groupID := 42]

# plot
p1 <- ggplot(data = STOCK, 
             aes(x = round, y = stock, fill = treatment, color = treatment, lty = treatment)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(limits = c(0, 4700), expand = c(0, 0)) +
  labs(y = "Wealth", x = "Period") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample")) +
  geom_point(mapping = aes(x = 10, y = 4613), col = "#b5b5b5") +
  annotate("text", x = 9, y = 4630, size = 3,
           label = "max", col = "#b5b5b5") +
  geom_line(data = maxPath, mapping = aes(x = x, y =y), col = "#b5b5b5", lty = 2) +
  guides(fill = "none") +
  layout +
  theme(legend.position = "top") +
  guides(lty = "none")
```

```{r growthHeterogeneityViz}
#| fig.cap: Average wealth over time across samples.

# plot
p2 <- ggplot(data = main,
       mapping = aes(x = round, y = stock, color = treatment, by = groupID)) +
  geom_line(alpha = 0.5) +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(limits = c(0, 2000),
                       expand = c(0, NA)) +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample")) +
  labs(y = "", x = "Period") +
  layout +
  guides(col = "none")


# assembling
p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = "top")
```

### Inequality

```{r summaryGini}
#| results: asis
#| warning: false
#| fig.cap: "test"

if(knitr::is_html_output()){
  type <- "html"
} else {
  type = "latex"
}

replication <- main[treatment == "replication" & round == 10, gini]
GMTV    <- main[treatment == "noPunish10" & round == 10, gini]

rs1 <- wilcox.test(replication, 
                   GMTV,
                   exact = FALSE)$p.value %>% 
  round(digits = 4) %>% 
  formatC(format = "f", 
          digits = 4)

```

```{r giniVariables}
originalGini    <- main[treatment == "noPunish10" & round == 10, mean(gini)] %>% round(digits = 2)
replicationGini <- main[treatment == "replication" & round == 10, mean(gini)] %>% round(digits = 2)
```

Given the different samples and the possibility of endogenous growth--which essentially is the main feature of the game--I ask whether and how the inequality grows _within_ groups. Figure 5 illustrates that inequality did grow: at the end of the game, the original and the replication groups exhibit an average Gini coefficient of `r originalGini` and `r replicationGini`, respectively.^[The two-sided rank sum test (comparing differences between samples) yields a p-Value of `r rs1` for the mean Gini coefficient in last round of the game.] Because every participant started with the same initial endowment (in _Period 0_, so to speak), every group started equally--with a Gini coefficient equaling zero.

Figure 6 shows that this initial state of equality ended with the first period already: both samples exhibit a stark incline in inequality before the second period started. From then on, the respective Gini coefficients grew slowly but continuously -- for both samples.

```{r giniDistributionViz}
#| fig.cap: Groups' Gini coefficients (within groups) at the end of the game

ggplot(data = main,
       mapping = aes(x = gini, fill = treatment, lty = treatment)) +
  geom_density(alpha = 0.5) +
  scale_x_continuous(limits = c(0, 1),
                       expand = c(0, NA)) +
  scale_y_continuous(limits = c(0, NA),
                       expand = c(0, NA)) +
  scale_fill_manual(values = c(cPrimary, cSecondary),
                    labels = c("Original Sample", "Replication Sample")) +
  guides(lty = "none") +
  geom_vline(xintercept = replicationGini,
             col = "#000000", alpha = 0.5,
             lty = 2) +
  geom_vline(xintercept = originalGini,
             col = "#000000", alpha = 0.5,
             lty = 1) +
    labs(title = "", 
       y = "", x = "Stock",
       caption = "Grey lines indicate means (dashed line = replication sample).") +
  layout +
  theme(legend.position = "top")
```

```{r}
#| fig.cap: Average Gini coefficient (within groups) over time across samples
#| 
tmp <- main[,
            lapply(.SD, mean, na.rm = TRUE),
            by = c("round", "treatment"),
            .SDcols = "gini"]

GINI <- rbind(tmp, list(0, "replication", 0), list(0, "noPunish10", 0))

ggplot(data = GINI, 
             aes(x = round, y = gini, fill = treatment, color = treatment, lty = treatment)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 0:10) +
  scale_y_continuous(limits = c(0, 0.25), expand = c(0, 0)) +
  labs(y = "Wealth", x = "Period") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample")) +
  guides(fill = "none") +
  layout +
  theme(legend.position = "top") +
  guides(lty = "none")
```

## Generalizability

# Conclusion

# Appendix

## A: Pure Replication


## B: Growth _and_ Inequality (exploratory)

In contrast to @GMTV2017, I did not ask how rich and poor groups differ. Instead, I was wondering, whether equal groups are wealthier. More precisely, does the Gini coefficient correlate with growth and wealth creation? To answer that question, Figure 7 applies a median split showing equal and unequal groups' wealth over time.

```{r plotStockByGini}
#| fig.cap: Average wealth over time across treatments.

# create equality indicator (just as highgdp in original data)
median <- main[round == 10,
               median(gini)]

equalGroups <- main[round == 10 & gini > median,
                    unique(groupID)] 

unequalGroups <- main[round == 10 & gini < median,
                      unique(groupID)]

main[groupID %in% equalGroups,
     equal := TRUE]

main[groupID %in% unequalGroups,
     equal := FALSE]

STOCKe <- main[equal == TRUE,
               lapply(.SD, mean, na.rm = TRUE),
               by = c("round", "treatment"),
               .SDcols = "stock"]

STOCKu <- main[equal == FALSE,
               lapply(.SD, mean, na.rm = TRUE),
               by = c("round", "treatment"),
               .SDcols = "stock"]

upperLimit <- 700


p1 <- ggplot(data = STOCKe, 
             aes(x = round, y = stock, fill = treatment, color = treatment, lty = treatment)) +
  layout +
  theme(legend.position="bottom") +
  # geom_vline(xintercept = 10, alpha = 0.66) +
  geom_line() +
  geom_point() +
  guides(lty = "none", fill = "none") +
  scale_x_continuous(name="",  breaks = 1:10) +
  scale_y_continuous(limits = c(0, upperLimit), expand = c(0, 0)) +
  labs(y = "Wealth (Equality)", x = "Period") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample"))

p2 <- ggplot(data = STOCKu, 
             aes(x = round, y = stock, fill = treatment, color = treatment, lty = treatment)) +
  layout +
  theme(legend.position="bottom") +
  # geom_vline(xintercept = 10, alpha = 0.66) +
  geom_line() +
  geom_point() +
  guides(lty = "none", fill = "none") +
  scale_x_continuous(name="",  breaks = 1:10) +
  scale_y_continuous(limits = c(0, upperLimit), expand = c(0, 0)) +
  labs(y = "Wealth (Inequality)", x = "Period") +
  scale_color_manual(values = c(cPrimary, cSecondary),
                     labels = c("Original Sample", "Replication Sample"))

p1 + p2 + plot_layout(guides = "collect") & theme(legend.position = "bottom")

rm(list = c("STOCKe", "STOCKu", "p1", "p2"))
```


